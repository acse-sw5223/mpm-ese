{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub and & Python (virtual) environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h3>Contact details:</h3>\n",
    "\n",
    " - Dr. Rhodri Nelson\n",
    " - Room 4.96 RSM building\n",
    " - email: rhodri.nelson@imperial.ac.uk\n",
    " - Teams: Tag me via <code>@Nelson, Rhodri B</code> (or DM me).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the year you'll continuously be interacting with Git and [GitHub](https://github.com/) (a hosting service for software development via the `Git` version control system). This will be used to\n",
    "- Distribute all course material\n",
    "- Distribute and submit individual assignments\n",
    "- Collaborate as teams during the group projects\n",
    "- Work on your individual research projects\n",
    "\n",
    "As a note, if you go into any job/position which involves software development you'll be using `Git` and `GitHub` or some similar version control and hosting service combination. Whilst `Git` is currently by far the most popular version control system (~80% market share?), one alternative is [Mecurial](https://www.mercurial-scm.org/) which has several internet hosting service [options available](https://www.mercurial-scm.org/wiki/MercurialHosting). Some alternative `Git` based hosting services include [Bitbucket](https://bitbucket.org) and [GitLab](https://about.gitlab.com/).\n",
    "\n",
    "**Getting comfortable with `Git` and `GitHub` will come through practice, one of the aims of this morning will be to start you on your way by working through some individual and group based exercises.**\n",
    "\n",
    "Along with utilising version control, another important aspect of developing Python software is \"sandboxing\" the development process through making use of virtual environments. There are several situations in which it can be useful to \"[sandbox](https://docs.python.org/3/library/venv.html)\" code into its own space so that other package installations cannot interfere with it, and so that it cannot interfere with them. We will cover this topic a little later in the day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Aims:\n",
    "\n",
    "- Familiarise ourselves with the basics of `Git` and `GitHub`.\n",
    "- Learn the basics of developing software as a 'team' using `GitHub`.\n",
    "- Introduce various virtual environment and container solutions including\n",
    "    - Venv\n",
    "    - Anaconda\n",
    "    - Docker\n",
    "- Explore in further detail how to work with Anaconda\n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `git` and `GitHub` basics\n",
    "\n",
    "Your personal computers should be configured as per the instructions provided in [laptop setup](https://github.com/ese-msc-2023/laptop-setup). During this process you should have configured your `git` username and password. (If not, please take a look at those instructions and configure your `git` settings during this session).\n",
    "\n",
    "There are plethora of good online `git` and `GitHub` tutorials - typing \"git tutorial\", \"github tutorial\" or similar into your search engine of choice will provide you with guides that will take you from the basics through to more advanced usage. We will now work through some of the basics.\n",
    "\n",
    "1. Create a repository via `GitHub`\n",
    "\n",
    "The first step is to create a repository via your `GitHub` account. A repository can be thought of as an individual 'project' which is under version control. Upon navigating to `https://github.com/yourusername?tab=repositories` you should see something like the following:\n",
    "\n",
    "<img src=\"figures/gh1.png\">\n",
    "\n",
    "Click on `New`, ensure you are selected as the `Owner` then give your repository a name, check the add `README` box and then create it.\n",
    "\n",
    "The repository will now exist on `GitHub` under your repositories.\n",
    "\n",
    "**NOTE:** You can of course create repositories in different manners. For example, you can write some code locally and then initialize the folder containing it as a `git` repo and later push this to `GitHub`. Feel free to try this later, but note that it's a little more involved and this route is not necessary for the time being.\n",
    "\n",
    "2. `clone` a repository\n",
    "\n",
    "To start modifying the contents of the freshly made repo, we'll **clone** it to our local machines. To do this, in a terminal (Windows users should ensure they are in a WSL Ubuntu terminal), navigate to the folder where you wish to clone your repository to and use the command\n",
    "```\n",
    "git clone https://github.com/yourusername/yourreponame.git\n",
    "```\n",
    "Typing `ls` (list) in your terminal will now reveal the presence of the freshly cloned folder. Navigate into your repository. Currently, only the `README.md` file will be present.\n",
    "\n",
    "3. `commit`ing changes\n",
    "\n",
    "If in the repository we type\n",
    "```\n",
    "git status\n",
    "```\n",
    "we'll output along the lines of\n",
    "```\n",
    "On branch main\n",
    "nothing to commit, working tree clean\n",
    "```\n",
    "This tells us we're on the branch `main` (we'll discuss branches more later, we'll just work directly on `main` for now) and that there have been no changes since the previous `commit`. Now, using your desired editor, open and modify the `README.md` (adding some random text is sufficient for now!). Save the changes and return to your terminal, then type `git status` again and notice the difference! We can also use the command\n",
    "```\n",
    "git diff\n",
    "```\n",
    "which will show the modifications in each file that has been changed.\n",
    "\n",
    "For the changes made to become an 'official' part of the codebase we now need to commit them. We can do that via\n",
    "```\n",
    "git commit -a -m \"an appropriate commit message.\"\n",
    "```\n",
    "This will create a 'check point' which knows the current state of the code. Type `git status` and `git diff` again and notice the output.\n",
    "\n",
    "4. `push` changes to `GitHub`\n",
    "\n",
    "These changes are now registered locally, but if you look at the `GitHub` page for this repository, nothing will have changed. For `GitHub` to know about the changes that have been made locally, we need to `push` them to the `remote` repository. We do this via\n",
    "```\n",
    "git push\n",
    "```\n",
    "After completing the `push`, if we go back to the repo url and refresh we'll see that the changes are now appearing.\n",
    "\n",
    "5. Adding new files under `git` version control\n",
    "\n",
    "Lets now look at how to add new files to our repository. Lets, somewhere in our repository, create a new `.py` file. We can make something simple for now, e.g.\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "a = np.sin(np.pi/2)\n",
    "\n",
    "print(a)\n",
    "```\n",
    "After creating our new file we can again run `git status`. We'll then see the new file appearing as `untracked`. If we wish to incorporate an untracked file under version control in the current repository we need to add it and then commit it as follows. Run\n",
    "```\n",
    "git add path_to/new_file.py\n",
    "```\n",
    "Before committing, it's a useful exercise at this point to run `git diff`. You'll see the contents of the new file appearing in this diff now. The commit the new file\n",
    "```\n",
    "git commit -a -m \"Add new_file.py\n",
    "```\n",
    "If we `git push` and then review our refreshed repo on `GitHub` we'll see the new file is there and the commit history has been updated.\n",
    "\n",
    "Next, take the time to carefully go through the above steps by yourselves, play around with your repository a little and be sure to ask questions!\n",
    "\n",
    "**Exercise:** Create a new jupyter notebook in your repository and run it. After this, run `git status`. What do you observe? Notice that as well as the notebook showing as an untracked file, some additional meta data files have been created - we don't want these to be tracked by git though so be careful not to add them! Be sure to only add the notebook itself to avoid cluttering the repository with unnecessary meta data files. If we know such meta data will often be created, but we don't want it tracked, can we get git to ignore it? Check out the [gitignore](https://git-scm.com/docs/gitignore) documentation to see if you can achieve this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborating with `git`/`GitHub`\n",
    "\n",
    "`GitHub` is an extremely useful and powerful tool for collaborative work - this will become _even_ more evident when we look at testing and continuous integration (CI) later in the module). Clearly, if you go on to work in any job where you're developing software, you'll need to use version control software in a collaborative manner. Also, you'll need to do this in each of your group projects this year! So lets have a little practice.\n",
    "\n",
    "**NOTE:** Items in **bold** have some instructions below to help you out with those steps!\n",
    "\n",
    "- Form teams of, ideally, 3 people (2-4 people is also fine).\n",
    "- Choose **one** members repository (created earlier today) as the repository the whole team will work on.\n",
    "- That member will need to **invite the other members of the team as collaborators**.\n",
    "- Each member should then clone the repository to a suitable location on their machine.\n",
    "- Once cloned, each member should **check out a new (independently named) branch**.\n",
    "- Next, independently, add a new file to the repository (.py, .txt, etc., it doesn't really matter). Add and commit the file to your branch.\n",
    "- **Push this new branch to `GitHub`**.\n",
    "- For your branch, **Create a Pull Request**. Then, as a team, **merge each pull request**.\n",
    "- On your local machines, `git checkout main` and then `git pull` to ensure your `main` branch is up to date with that existing on `GitHub`.\n",
    "- **Delete your old branch** that has now been merged.\n",
    "- Next, each member should (separately) create a new branch (from the up to date `main`). In the `.py` file created previously, each add a new function (anything simple will do, just make sure each function everyone is adding is a little different). When done, commit and then push the new branch to `GitHub`. Create pull requests again. Choose one branch to merge <- _this should work fine_. However, when trying to merge the next branch you'll probably encounter a merge conflict! I'll do a live demo demonstrating _one_ way to handle merge conflicts later, but can you attempt utilise [rebase](https://git-scm.com/docs/git-rebase) to fix this yourselves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inviting collaborators to `GitHub` repos\n",
    "\n",
    "If you wish to allow other users read and write access to a repository in your workspace you need to add them with the correct permissions.\n",
    "\n",
    "Click on the repository settings tab:\n",
    "\n",
    "<img src=\"figures/gh2.png\">\n",
    "\n",
    "The, click on `Collaborators` in the left hand side bar and you should see something like the following:\n",
    "\n",
    "<img src=\"figures/gh3.png\">\n",
    "\n",
    "Use the `Add people` button to add all your group members. Ensure they have Read/Write access or above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating branches\n",
    "\n",
    "Utilising the branch functionality is among the most important, and useful, aspects of using version control software. Hence, it's important to get used to it!\n",
    "\n",
    "Simply speaking, a branch is a separate version of the main repository (there are more exact and technical definitions but we don't need to worry about that for now). When working on a new feature, for example, it's useful to create a branch an experiment. This can then be eventually merged with the main branch, but if things don't work out it can be deleted with the main core untouched/unharmed! They're useful for many many more reasons, that you'll start to see as you make use of their functionality.\n",
    "\n",
    "To check which branch you're currently on you can run\n",
    "```\n",
    "git branch\n",
    "```\n",
    "The current branch will be marked with an \\*. To create a new branch you can run:\n",
    "```\n",
    "git checkout -b new_branch_name\n",
    "```\n",
    "(Run `git branch` again now to see how things have changed!). The move between existing branch you can run\n",
    "```\n",
    "git checkout existing_branch_main\n",
    "```\n",
    "e.g., to move back to the main branch from your newly created branch you can simply run\n",
    "```\n",
    "git checkout main\n",
    "```\n",
    "(But remember to move back to your new/development branch before making changes to the code!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pushing new (locally created) branches to `GitHub`\n",
    "\n",
    "After creating a new branch locally, to push this to `GitHub` you'll need to run\n",
    "```\n",
    "git push -u origin new_branch_name\n",
    "```\n",
    "Following this, the branch will be visible on the branches tab of your `GitHub` repo:\n",
    "\n",
    "<img src=\"figures/gh4.png\">\n",
    "\n",
    "Now that `GitHub` knows about the branch, if we push any more changes to the branch we can simply use\n",
    "```\n",
    "git push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and merging pull requests\n",
    "\n",
    "Creating and merging pull requests are another important aspect of managing `GitHub` repositories. If we wish to merge the changes of a particular branch into the `main` branch it's good practice to open a pull request to do this.\n",
    "\n",
    "There are many ways to do this, but here's one. If you click on the `branches` tab (shown in the figure above) you'll see something along the lines of:\n",
    "\n",
    "<img src=\"figures/gh5.png\">\n",
    "\n",
    "Next to the branch you wish to merge, you can click the `Create pull request` button and follow the instructions. In the `Pull requests` (PR) tab of the main repo, you'll then see the pull request appear. This view has many useful tools, where developers can see and comment on the changes to the code base etc. Providing all is 'ok' with the PR, when opening the PR you'll see the `Merge pull request` button as green:\n",
    "\n",
    "<img src=\"figures/gh6.png\">\n",
    "\n",
    "**Important:** Just because the button is green it doesn't mean the PR is ready to be merged (it just means GH knows how to merge it without any conflicts emerging). The changes introduced by a PR should be carefully checked by users to ensure everything is as they wish.\n",
    "\n",
    "After clicking the `Merge pull request` button the changes will then be live in the `Main` branch. After this, remember to update your main locally by checking out the main branch and running a `git pull`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual environments\n",
    "\n",
    "### Why do we need virtual environments?\n",
    "\n",
    "You're now somewhat familiar with the `Python` package manager `pip`. Consider the following two 'dummy' packages and their requirements:\n",
    "\n",
    "- Package **A**, has the following dependencies:\n",
    "    - package a, version >= 1.0\n",
    "    - package b, version <=1.2\n",
    "    - package c, version >= 2.2\n",
    "    - package d, version >= 5.0\n",
    "- Package **B**, requires:\n",
    "    - package a, version >= 1.0\n",
    "    - package b, version >= 1.3\n",
    "    - package e, version 1.0\n",
    "    - package f, version >= 7.0.\n",
    "\n",
    "Reviewing the above, we can see there is a conflict for the dependency `package b`. Clearly, using `pip` to switch between two versions of package `b` every time want to use **A** or **B** is not a good solution. But further, in reality, when working on larger development projects such dependency conflicts may arise for several, or even dozens(!), of packages. Clearly, a better solution is to have both versions of the software installed and an easy way to switch between the appropriate environment when using either **A** or **B**. This is where _virtual environments_ come in handy.   \n",
    "\n",
    "A virtual environment is a tool that helps to keep dependencies required by different projects separate by creating isolated python virtual environments for them. This is one of the most important tools that most Python developers use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "_**As a note**_ (no need to delve too deeply into this at the current time), virtual environments modify various `environment variables` upon activation, allowing them to handle various versions of the same package etc. \n",
    "\n",
    "From Wikipedia (https://en.wikipedia.org/wiki/Environment_variable):\n",
    "\n",
    "_An environment variable is a dynamic-named value that can affect the way running processes will behave on a computer. They are part of the environment in which a process runs. For example, a running process can query the value of the TEMP environment variable to discover a suitable location to store temporary files, or the HOME or USERPROFILE variable to find the directory structure owned by the user running the process._\n",
    "\n",
    "As an example, one important environment variable is the **PATH** variable. To view the value of this variable, within a terminal you can type\n",
    "```bash\n",
    "echo $PATH\n",
    "```\n",
    "The variable is a list of directory paths. When the user types a command without providing the full path, this list is checked to see whether it contains a path that leads to the command.\n",
    "\n",
    "In summary, the values of environment variables govern how certain as aspects of your environment function, e.g. which executables and libraries will be called/accessed by default, or which options will be used when executing certain commands.\n",
    "\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When and where to use a virtual environment?\n",
    "\n",
    "By default, every project on your system will use the same directories to store and retrieve site packages (third party libraries). Why does this matter? In the above example of two projects, you have two versions of package `b`. This is a real problem for Python since it can't differentiate between versions in the \"site-packages\" directory. So both v1.2 and v1.3 would reside in the same directory with the same name. This is where virtual environments come into play. To solve this problem, we just need to create two separate virtual environments, one for each project. The great thing about this is that there are no limits to the number of environments you can have since they're just directories containing a few scripts.\n",
    "\n",
    "Along with the above example, we may also want to make use of virtual environments because\n",
    "- Sometimes packages have the same name, but do different things, creating a namespace clash.\n",
    "- Sometimes you need a clean environment to test your package dependencies in order to write your `requirements.txt` file (we will talk more about such files later).\n",
    "\n",
    "### venv\n",
    " \n",
    "Python comes with an [inbuilt library](https://docs.python.org/3/library/venv.html) called `venv` which can be used to create so-called \"virtual environments\". Inside a virtual environment, only the packages and tools you explicitly choose to copy across are available, and only at the version numbers you request. This gives a quick, easy access to a \"clean\" system, be it for testing, or to run mutually incompatible software.\n",
    "\n",
    "To create a new `venv` environment you can run a command like\n",
    "```bash\n",
    "python -m venv foo\n",
    "python -m venv environmental name\n",
    "```\n",
    "or, on systems with both Python 2 and Python 3 available,\n",
    "```bash\n",
    "python3 -m venv foo\n",
    "python3 -m venv environmental name\n",
    "```\n",
    "\n",
    "This will create a new directory `foo/` containing the files relevant to that virtual environment. To load the environment run\n",
    "```bash\n",
    "source foo/bin/activate\n",
    "```\n",
    "\n",
    "To disable the environment run\n",
    "```bash\n",
    "deactivate\n",
    "```\n",
    "\n",
    "\n",
    "##### Building a `requirements.txt` file using `venv`\n",
    "\n",
    "Switching to a `venv` environment is one way to build up a short list of required packages for a new project. You can start up a blank environment and then try to build and run your code. If a dependency is missing, this should fail with an `ImportError` message, something along the lines of\n",
    "\n",
    "```bash\n",
    "Traceback (most recent call last):\n",
    "   File \"<string>\", line 1, in <module>\n",
    "   File \"/tmp/pip-ukwnrb23-build/setup.py\", line 5, in <module>\n",
    "     from numpy import get_include\n",
    "   ImportError: No module named 'numpy'\n",
    "```\n",
    "\n",
    "Ideally you will then be able to recognise the missing dependency (in this case `numpy`) and fix it by running a command like `pip install numpy`. After repeating as needed to fix any further requirements you can generate a `requirements.txt` compatible list for your Python environment (with the command `pip freeze`, this also lists the currently installed version)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class= exercise>\n",
    "\n",
    "<h4>Exercise : Make a `venv`</h4>\n",
    "<p>Create your own <code>venv</code> environment, giving it a name of your choice. Activate it. Note the difference it makes to your command prompt.</p>\n",
    "\n",
    "<p>Double check the installed package list using <code>pip list</code>. Install a package into the virtual environment (such as <code>matplotlib</code>) using <code>pip</code>. Check that the list of installed packages inside the environment changes.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some other tools (before we talk about Anaconda)\n",
    "\n",
    "- [**virtualenv**](https://virtualenv.pypa.io/en/stable/)\n",
    "\n",
    "This is a popular tool for creating isolated Python environments for Python libraries. **virtualenv** functions by installing various files in a directory (e.g. `env/`), and then modifying the `PATH` environment variable to prefix it with a custom bin directory (e.g. `env/bin/`). An exact copy of the python or python3 binary is placed in this directory, but Python is programmed to look for libraries relative to its path first, in the environment directory. It's not part of Python's standard library, but is officially blessed by the PyPA (Python Packaging Authority). Once activated, you can install packages in the virtual environment using `pip`.\n",
    "\n",
    "- [**docker**](https://www.docker.com/)\n",
    "\n",
    "A virtualenv only encapsulates Python dependencies. A Docker container encapsulates an entire operating system (OS). With a Python virtualenv, you can easily switch between Python versions and dependencies, but you're stuck with your host OS. With a Docker image, you can swap out the entire OS - install and run Python on Ubuntu, Debian, Alpine, even Windows Server Core. There are Docker images out there with every combination of OS and Python versions you can think of, ready to pull down and use on any system with Docker installed.\n",
    "\n",
    "Tools such as Docker are excellent for testing software packages and cross operating system/hardware compatibility. For software development, tools such as `conda` are generally more convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Miniconda (Anaconda Python)?\n",
    "\n",
    "Anaconda is an open-source distribution of Python that simplifies package management. It comes with applications such as Jupyter Notebook, the Conda environment manager, and Pip for package installation and management. Anaconda also comes with hundreds of Python packages such as `matplotlib`, `NumPy`, `SymPy` and so forth.\n",
    "\n",
    "It eliminates the need to install common applications separately and will (generally - although not always) make installing Python on your computer much easier.\n",
    "\n",
    "[Miniconda](https://docs.conda.io/en/latest/miniconda.html#) is a minimal (lightweight) conda installer. (It lacks the `GUI`s that come with the full installation, but during this course it will more convenient to get used to using the terminal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_ that a large range of helpful Anaconda tutorials can be found [online](https://docs.anaconda.com/anaconda/navigator/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the usage of `conda`, let us together work through an exercise.\n",
    "\n",
    "For this we will fork, then clone and play around with a dummy package made for this purpose.\n",
    "\n",
    "Go to the address https://github.com/rhodrin/environments_mpm and click on the `fork` button as shown in image below (make sure you're logged into your Github account before doing this):\n",
    "\n",
    "<img src=\"figures/fork.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then clone the forked package (**Make sure you're in an appropriate folder before performing the clone**)- in a terminal type\n",
    "```bash\n",
    "git clone https://github.com/<my github name>/environments_mpm.git\n",
    "```\n",
    "The package can also be cloned via the Visual Studio Code GUI.\n",
    "\n",
    "In the base folder notice the presence of both an `environment.yml` file and a `requirements.txt` file. The `environment.yml` file defines the Anaconda virtual environment we wish to create. If we look at its contents, we see (importantly) `name: envtest`, specifying the name of the environment we're going to create and some dependencies. We'll talk more about them later, but now let us create a 'conda' environment. In the cloned directory type \n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "When that command is complete type\n",
    "```bash\n",
    "conda activate envtest\n",
    "```\n",
    "and following this (making sure that the your terminal has now been modified such that `(envtest)` is appearing) type\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "to install the `envtest` package (recall that the operations performed by this command are governed by the contents of `setup.py`). You can type\n",
    "```bash\n",
    "pip show envtest\n",
    "```\n",
    "to ensure it has installed ok - if present you should see something similar to the following:\n",
    "```bash\n",
    "Name: envtest\n",
    "Version: 0.1.dev2+g13df730\n",
    "Summary: Playing with virtual environments.\n",
    "Home-page: https://github.com/ese-msc-2021/modern-programming-methods\n",
    "Author: Imperial College London\n",
    "Author-email: rhodri.nelson@imperial.ac.uk\n",
    "License: UNKNOWN\n",
    "Location: /data/teaching/msc-ese/misc/environments_mpm_final\n",
    "Requires: \n",
    "Required-by:\n",
    "```\n",
    "Once that is done, let us view the contents of `requirements.txt`. Currently, we see that only one dependency is listed, that of `numpy` (version > 1.16). Lets install this dependency via\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "Now, to check everything is correctly set up, from within the base directory run\n",
    "```bash\n",
    "python scripts/random_numpy_array.py\n",
    "```\n",
    "You should see output along the lines of\n",
    "```bash\n",
    "[[0.22330655 0.07439368 0.69014812]\n",
    " [0.90354345 0.06734495 0.13096386]\n",
    " [0.22487417 0.6394524  0.41603555]]\n",
    "```\n",
    "(noting that the actual numbers you see will be slightly different since the routine is generating a 3x3 array of random numbers between 0 and 1).\n",
    "\n",
    "Also, lets now look at the result of `echo $PATH` again. Notice the modified value within our environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets add a few further functions, dependencies and scripts to our repository.\n",
    "\n",
    "In the file `envtest/builtins.py`:\n",
    " - add the following two lines right after the existing import\n",
    "```python\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import misc\n",
    "```\n",
    " - Modify `__all__ = ['rand_array']` to `__all__ = ['rand_array', 'smooth_image']`\n",
    " - Add the following function:\n",
    "```python\n",
    "def smooth_image(a, sigma=1):\n",
    "    return gaussian_filter(a, sigma=sigma)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, modify the file `scripts/smooth_image.py` so that it reads (i.e. remove any existing text):\n",
    "```python\n",
    "from envtest import smooth_image\n",
    "\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image = misc.ascent()\n",
    "sigma = 5\n",
    "\n",
    "smoothed_image = smooth_image(image, sigma)\n",
    "\n",
    "f = plt.figure()\n",
    "f.add_subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "f.add_subplot(1, 2, 2)\n",
    "plt.imshow(smoothed_image)\n",
    "plt.show(block=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, if we try running this script, e.g. `python scripts/smooth_image.py`, we'll see an error of the following form:\n",
    "```bash\n",
    "Traceback (most recent call last):\n",
    "  File \"/data/teaching/msc-ese/misc/environments_mpm/scripts/smooth_image.py\", line 1, in <module>\n",
    "    from envtest import smooth_image\n",
    "  File \"/data/teaching/msc-ese/misc/environments_mpm/envtest/__init__.py\", line 1, in <module>\n",
    "    from .builtins import *\n",
    "  File \"/data/teaching/msc-ese/misc/environments_mpm/envtest/builtins.py\", line 2, in <module>\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "ModuleNotFoundError: No module named 'scipy'\n",
    "```\n",
    "This is of course because we have not yet installed the 'new' required dependencies. These are `scipy` and `matplotlib`, so lets add them to our `requirements.txt` file and install them. That is, modify `requirements.txt` so that is now reads:\n",
    "```\n",
    "numpy>1.16\n",
    "scipy\n",
    "matplotlib\n",
    "```\n",
    "and then type\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "again. (Note that a `pip install scipy` etc would also do the job, but since we want to keep our requirements file up to date it doesn't hurt to use it directly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this, after running the script we should see a plot with the original image on the left and the smoothed image on the right\n",
    "\n",
    "<img src=\"figures/smoothed.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go through this exercise once more. To `builtins.py` add the following function:\n",
    "```python\n",
    "def my_mat_solve(A, b):\n",
    "    return A.inv()*b\n",
    "```\n",
    "Remember that we need to make this function visible within the package and hence must modify the `__all__ = [...]` line appropriately.\n",
    "\n",
    "Then, lets add a new script to make use of it. In the `scripts` folder create a new file called `solve_matrix_equation.py` and within it paste the following text\n",
    "```python\n",
    "from envtest import my_mat_solve\n",
    "\n",
    "from sympy.matrices import Matrix, MatrixSymbol\n",
    "\n",
    "# Call function to solve the linear equation A*x=b symbolically\n",
    "\n",
    "A = Matrix([[2, 1, 3], [4, 7, 1], [2, 6, 8]])\n",
    "b = Matrix(MatrixSymbol('b', 3, 1))\n",
    "x = my_mat_solve(A, b)\n",
    "\n",
    "print(x)\n",
    "```\n",
    "Our new dependency is `SymPy`. Hence, lets also add that to `requirements.txt` (simply add `sympy` to the end of the file) and then repeat the install command we used previously.\n",
    "\n",
    "To ensure the newly added script runs successfully, upon execution we should see the following output:\n",
    "```bash\n",
    "Matrix([[b[0, 0]/2 + b[1, 0]/10 - b[2, 0]/5], [-3*b[0, 0]/10 + b[1, 0]/10 + b[2, 0]/10], [b[0, 0]/10 - b[1, 0]/10 + b[2, 0]/10]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Finalizing our repository\n",
    "\n",
    "We'll now update our `environment.yml` file and then rebuild our environment to ensure that within our updated environment everything works correctly 'out of the box'.\n",
    "- First, lets check the status of our repository and make sure we add any new files:\n",
    "```bash\n",
    "git status\n",
    "```\n",
    "will return something along the lines of\n",
    "```bash\n",
    "On branch master\n",
    "Your branch is up-to-date with 'origin/master'.\n",
    "```\n",
    "```bash\n",
    "Changes not staged for commit:\n",
    "  (use \"git add <file>...\" to update what will be committed)\n",
    "  (use \"git restore <file>...\" to discard changes in working directory)\n",
    "\tmodified:   environment.yml\n",
    "\tmodified:   envtest/builtins.py\n",
    "\tmodified:   requirements.txt\n",
    "\tmodified:   scripts/smooth_image.py\n",
    "```\n",
    "```bash\n",
    "Untracked files:\n",
    "  (use \"git add <file>...\" to include in what will be committed)\n",
    "\t.eggs/\n",
    "\tenvtest.egg-info/\n",
    "\tenvtest/__pycache__/\n",
    "\tscripts/solve_matrix_equation.py\n",
    "```\n",
    "The import untracked file we need to add is `scripts/solve_matrix_equation.py` - the others are meta-data **we do not want** under version control. We can add it through\n",
    "```bash\n",
    "git add scripts/solve_matrix_equation.py\n",
    "```\n",
    "- Next, commit the changes we've made via\n",
    "```bash\n",
    "git commit -a -m \"<my commit message>\"\n",
    "```\n",
    "- Then, add a further function of your choice to `builtins.py` and an accompanying script to utilize this function. Ensure that this new function requires _at least_ one new additional dependency (remember to modify `requirements.txt` etc. appropriately). If you're not sure what new package to use, how about a quick [Pandas example](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)? (You'll learn more about Pandas later in this course).\n",
    "- When this is done, and you've confirmed that the new script is working as intended, modify the `environment.yml` and add all new dependencies to it. That is, is should now look along the lines of the following but with **your** additional dependencies also added:\n",
    "```\n",
    "name: envtest\n",
    "channels:\n",
    "  - defaults\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python>=3.6,<3.10\n",
    "  - pip\n",
    "  - numpy>1.16\n",
    "  - scipy\n",
    "  - matplotlib\n",
    "  - sympy\n",
    "```\n",
    "- When this is done, commit all these changes to the repository, remembering to add any new files first - e.g.\n",
    "```bash\n",
    "git add scripts/my_new_script.py\n",
    "```\n",
    "followed by\n",
    "```bash\n",
    "git commit -a -m \"<my commit message>\"\n",
    "```\n",
    "- Push these changes to github\n",
    "```bash\n",
    "git push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Next, ensure your github repository has updated correctly - you can check this through checking some files in your web-browser.\n",
    "\n",
    "Now, as a test, we'll deactivate and delete our environment and remake it using our updated `environments.yml` file.\n",
    "\n",
    "The required commands are as follows:\n",
    " - `conda deactivate`\n",
    " - `conda remove --name envtest --all`\n",
    " - `conda env create -f environment.yml`\n",
    " \n",
    "Then, once the environment has been created activate it again via `conda activate envtest`. Note that if we now look at `pip list` we will see the full list of required packages along with their dependencies have been installed already.\n",
    "\n",
    "If you happen to run into any issues there's a 'completed' example of the repository available at [here](https://github.com/rhodrin/environments_mpm_final) - **Remember to fork it first if you want to play around and edit it**.\n",
    "\n",
    "(**NOTE**: In practice we'd generally create a new environment with a different name to test everything is working, but since this is a 'dummy' package and to avoid 'clutter' we'll do it this way for the time being)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final note, think about why is it important to have both `environment.yml` and `requirements.txt` files.\n",
    "\n",
    "- The `environment.yml` was used only when creating our environment. Remember it was useful to have the `requirements.txt` file to install the required packages when developing our environment. (Although we could have also continuously updated our environment file and then updated our environment via `conda env update -f environment.yml`).\n",
    "- In any case, we generally want both for people making use of our package who are not using `Anaconda`. As we saw earlier, we could use such a requirements file in `venv`.\n",
    "- Additionally, what if we want some packages to not be installed automatically when creating our environment? For various reasons, we may with to have an, e.g. `requirements-optional.txt` file present (generally the packages listed in `environment.yml` and `requirements.txt` should be in sync unless there's a good reason for them not to be). Any such optional requirements can be installed via the `pip install -r ... .txt` command once again.\n",
    "- There are other `conda` package vs `pip` package reasons also, but that's something that may be raised later in the course when necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
